\chapter{Results}
In the following chapter we want to test the new surrogate models. Before going straight to the Bayesian optimization experiments
we want to test out the performance of as probabilistic regression models. In this chapter to design 4 test functions, 
which are defined to make it hard for the GP to perform well. Thereby we might find regression models, which is better?!
When this is established we want to test out the performance as a Bayesian optimization rutine!

Firstly an overview of the implementation!. 

\todo{Lav systematiske resultater. Udvælg functionsklasser at kigge på}

<reproducer resultater fra Arayns thesis>
Egne forsøg med SPN og mixture regression


\section{Implementation}
The Gaussian process regression is implemented using the Scikit-learn Gaussian process
implementation with the Matern kernel with $\nu=1.5$ and the y-values are normalized for
the prior distribution to be reasonable (mean 0 and variance 1). The lengthscale is optimized by
maximizing the marginalized likelihood using the limited memory quasi-newton solver with bounds
l-bfgs-b with 200 restarts. 

The Bayesian neural network is implemented using Numpyro - which is a python library for
probabilistic machine learning, developed by some of the people behind Pyro, but instead of using
PyTorch as backend, Numpyro uses Jax. This allows for a significantly large speedup when doing MCMC,
i.e. NUTS sampling. This was however still very slow and we, therefore, limited the network size to a
small 3 layer with 10 nodes on each layer network. The prior distribution for weights is a standard
normal distribution, and the bias normal priors are sat 
a bit less restrictive with a standard deviation of 2 instead. 
This is reasonable since the data is always standardized. 



\begin{table}[H]
  \centering
  \resizebox{\textwidth}{!}{\begin{tabular}[t]{p{.20\textwidth} | p{.40\textwidth}  | p{.40\textwidth}}
  \textbf{Model}       & \textbf{Specification}    &   \textbf{Training} \\ \hline
  BNN& 
  \begin{tabular}[t]{l}
    3 layers of 50 tanh nodes\\ 
    $p(\textbf{w}, b) \sim \mathcal{N}(0,1)$ \\
    $p(\sigma) \sim \text{InvGa}(1000,1)$ 
  \end{tabular} &
  \begin{tabular}[t]{l}
    NUTS(500 burn-in, 500 samples) 
  \end{tabular} \\\hline

  BOHamiANN& 
  \begin{tabular}[t]{l}
    3 layers of 50 tanh nodes\\ 
    $p(\textbf{w}, b) \sim \mathcal{N}(0, \sigma_{w})$ \\
    $p(\sigma) \sim \text{LogNormal}(??)$ \\
    $p(\sigma_{w}) \sim \text{Gamma}(??)$
  \end{tabular} &
  \begin{tabular}[t]{l}
    Adaptive stochatic HMC \\
    (1000 burn-in, every 5 of 2000 samples) 
  \end{tabular} \\\hline

  GP& 
  \begin{tabular}[t]{l}
    Mantern kernel 52
  \end{tabular} &
  \begin{tabular}[t]{l}
    Maximize marginalized likelihood \\
    20 restarts of BFGS optimization
  \end{tabular} \\\hline

  GMR& 
  \begin{tabular}[t]{l}
    Training sklearn GMM, \\
    EM of MLE with 3 restarts.\\
    pluggin into GMR software \cite{GMR}. 
  \end{tabular} &
  \begin{tabular}[t]{l}
    BO Cross-validation 30 fold, \\
    tuning number of components \\ 
    and prior weight
  \end{tabular} \\\hline

  SPN& 
  \begin{tabular}[t]{l}
    Trained using 3 restarts of EM of MAP,\\  
  \end{tabular} &
  \begin{tabular}[t]{l}
    BO Cross-validation 30 fold,\\
     tuning: hyperpriors and prior weight
  \end{tabular} \\\hline

  KDE& 
  \begin{tabular}[t]{l}
    Gaussian around all datapoints \\
    with a x-variance and y-variance
  \end{tabular} &
  \begin{tabular}[t]{l}
    BO Cross-validation 30 fold,\\
     testing x-variance and y-variance and prior weight\\ 
  \end{tabular} \\\hline
  \end{tabular}}
  \caption{Overview of chosen models  
          }
\end{table}
%\subsection{Model definintions}
Whereas a true Bayesian would not choose a specific type of model, but using all models
, however, this would indeed be infeasible. We need to limit the scope, 
For the GP, we do 20 restarts in the emperical maximization. And the manteen kernel prior
with $\nu = 2.5$. 
BNN, is a 50x50x50 tanh layers with standard Gaussain priors on. And a inverse gamma (1000, 1)
prior on the noise. Trained with 100 burn in and 100 samples. 
BOHAMIANN is similar but uses a different noise prior, and trains using adaptive HMC method. 
The mixture models are trained using crossvalidation scored on the mean predictive log .. posterior
(formally speaking this is not a likelihood, but we will keep it as it is almost the same)
The tuning parameters 
We do 40 iterations 
SPN is trained using EM with maximum 1000 epochs (is terminated if the progress is stalling). 
it is trained 2 times. \todo{Lav den historie}
GMR is trained using EM but this is done by the sklearn software. 

\subsection{standardized data}
Before the data reach any of the models, it is standardized. Which is 
a scaling and translation such that the datas empirical mean and standard deviation are 0 and 1, respectively. 
In that way is much easier to control the parameters in the models, since the data it fits and predicts
is always on the same scale. The transformation is as follows, the first time the models see the data, 
the empirical mean and standard deviation is recorded both for $x$ and $y$, (note $x$ can be a vector),
giving $\mu_x$,$\mu_y$, $\sigma_x$and $\sigma_y$.
Next, all data is transformed using the transformation, 

$$T_x(\cdot) := \frac{\cdot-\mu_x}{\sigma_x}$$

When we predict the $x$ is transformed, the model output a prediction 
and then the inverse transform is mapping the prediction from the standardised
domain to the original domain, 
 $T^{-1}_y(\hat y) := \hat y \cdot \sigma_x+\mu_x$

 \section{Regression analysis methodology}
 As described in the previous sections, an essential part of Bayesian optimization and the decision
 theory built around Bayesian optimization is that the regression model is correct. We will therefore
 look at how good the regression models are in terms of accurate prediction and 
 correct uncertainty estimation. 
 
 \subsubsection{uncertainty quantification}
 The probibalistic model is given as 
 $$p(y|x,\mathcal{D}) = \mathcal{N}(y|\mu_{\mathcal{D}}(x), \sigma_{\mathcal{D}}^2(x))$$
 where the mean, and variance functions are different for all the models. 
 Given a trained model, we quantify its ability to capture uncertainty with the average
 predictive likelihood/ probability of the observation, given a test input $x_i$ the
 the density of predictive distribution is evaluated in the coresponding test output $y_i$,
 
 $$\overline{p(y_i|x_i,\mathcal{D})} := \frac{1}{n}\sum_{i=1}^n p(y_i|x_i,\mathcal{D})$$
 note that the above might lead to that it is more important to classify one test point
 really well, so what we actually would rather test is the test point evaluated in the predictive
 posterior $$p(\textbf{y}|\textbf{x}, \mathcal{D}) = \prod p(y_i|x_i, \mathcal{D})$$
 where it is much more convinient to deal with it in the log space, 
  $$\log p(\textbf{y}|\textbf{x}, \mathcal{D}) = \sum \log p(y_i|x_i, \mathcal{D})$$
 which makes it convinient to get the mean log prediction. 
 
 there the bigger the mean predictive likelihood is, the better. \todo{it is not called predictive
 likelihood!!}
 
 \subsubsection{prediction quantification}
 Here we use the mean absolute error to quantify the prediction error. The i'th test point is
 $(x_i,y_i)$ and the mean absolute error is given as, 
 $MAE :=\frac{1}{n}\sum_{i=1}^n |\mu_{\mathcal{D}}(x_i) - y_i| $
 
 \subsubsection{Benchmark surrogate model}
 We will benchmark our different regression models againt a simple emperical mean and
 emperical std. normal distribution benchmark, 
 $$p(y|x\mathcal{D}) = \mathcal{N}(y| \bar{\textbf{y}} , \bar{\sigma}^2 (\textbf{y}))$$
 
 where $\bar{\textbf{y}} = \frac{1}{n}\sum_{i=1}^n \textbf{y}_i $ and $\bar{\sigma}^2 (\textbf{y}))
 = \frac{1}{n-1}\sum_{i=1}^n (\textbf{y}_i-\bar{\textbf{y}})^2 .$ In the context of Bayesian
 optimization, it will not provide new candidate point, as all points are equally good, therefore
 it coresponds to random search, and will be used as random search benchmark. 


\newpage
\section{Model compartment on test problems (regression)}
% Experiment section. For each experiment
%  1. Introduction. What is the purpose of the experiment
%  2. Data, materials, methods. Exactly how was the experiment conducted.
%  3. Results
%  4. Discussion. Conclusions.
Bayesian optimization is typically performed on black-box functions, and thereby the Bayesian
regression model is trained on data from all kinds of underlying problems. Now we want to test the
performance of different regression models on different types of 1D problems, all in the interval $x
\in [-100,100]$:

\begin{itemize}
  \item Test 1: A well-bahaved sine-function,
  \item Test 2: A highly discontinuous function,
  \item Test 3: A multi-modal objective function,
  \item Test 4: An anisotropic objective function.
\end{itemize}
The figures are presented here,

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.24\textwidth}
   \includegraphics[width=\textwidth]{Figures/reg_illustrations/all_reg_figures/Test1.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{Figures/reg_illustrations/all_reg_figures/Test2.pdf}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{Figures/reg_illustrations/all_reg_figures/Test3c.pdf}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.24\textwidth}
     \includegraphics[width=\textwidth]{Figures/reg_illustrations/all_reg_figures/Test4c.pdf}
    \end{minipage}

  \label{TEST_problems}
\end{figure}


It is common to have many parameters to tune in Bayesian optimization (in 1D a human could
potentially assist the surrogate model since the regression can be plotted and judged by eye).
Nevertheless, we will keep the domain in 1D to establish  
a more informative evaluation of the model performance.
This will establish some intuition about the models and 

% \begin{figure}[h]
%   \centering
%   \begin{minipage}[b]{0.44\textwidth}
%    \includegraphics[width=\textwidth]{Figures/results_regression/Test1_dim_1_0.pdf}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.44\textwidth}
%     \includegraphics[width=\textwidth]{Figures/results_regression/Test2_dim_1_0.pdf}
%    \end{minipage}
%   %  \hfill
%    \begin{minipage}[b]{0.44\textwidth}
%     \includegraphics[width=\textwidth]{Figures/results_regression/Test3b_dim_1_0.pdf}
%    \end{minipage}
%    \hfill
%    \begin{minipage}[b]{0.44\textwidth}
%      \includegraphics[width=\textwidth]{Figures/results_regression/Test4b_dim_1_0.pdf}
%     \end{minipage}

%   \label{regression_performance}
% \end{figure}


\subsection*{Test1: Well-behaved problem}
The first problem will establish some benchmark since this is a simple function to fit. Its exact definition is,
$$f(x) = x\cdot \sin(\frac{x}{50} \pi) + 150 + \frac{x}{10} + \sin(x) \hspace{0.5cm} x \in [-100,100],$$
giving a smooth wave function, with the optimium around $-80$. Note that $\sin(x)\in [-1,1]$ contribute with
some small high frequency surface waves. 

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[width=\textwidth]{Figures/results_regression/Test1_dim_1_0.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{Figures/results_regression/Test1_dim_1_1.pdf}
   \end{minipage}
  \caption{Mean relative error (point estimate using the predictive mean) (left) and exponential mean predictive log probalility (right) as
  functions of number of training data points. All curves reprecent the average across 10 seeded runs for each
  model.}
  \label{Test1_reg_plot}
\end{figure}

First of all, we see that all the methods are indeed performing better than the mean prediction
(black). The average relative error for the mean prediction is constant at 30\%. All models, besides the
Gaussian mixture regression (GMR), have an average relative error of less than 10\% after just 20 training
points. Including more data, the Bayesian neural network and the Gaussian process have the best mean prediction, 
the third discriminative model, BOHamiANN, seems here to be a weak learner. at 30 data points, it stays at the
same error - even when being presented for 316 training data points in the end. 

Looking at the right plot in Figure \ref{Test1_reg_plot}, we see that the generative models after 20
training points, have an increasingly better uncertainty quantification compared with using the empirical
standard deviation. %We have been choosing the hyper parameters of the generative models using crossvalidation.
The discriminative models on the other hand perform worse than the empirical standard deviation, 
especially the GP is doing exceptionally bad - its overconfident, the reason can be seen in Figure \ref{Test1_reg_visual_1},  
showing one of the 10 runs for 23 data points. The GP is so certain on some predictions that it assigns
almost 0 probability to some of the 10000 test points (i.e the we test all of the line from -100 to 100),
 yielding very low mean log predictive likelihood. 
%  The Bayesian neural networks learning curve stagnates around 100 data points, however,
% it provides a decent mean log predictive likelihood. BOHamiANN performs well in the beginning 
% but seems not expressive enough for this task. The architecture of the neural network is besides
% they use a log-normal prior on the variance and a hyper prior on the variance parameter of the weights.
% But it seems like the algorithm does not converge?. The mixture models are crossvalidated to maximize
% the predive likelihood, 
% To get a deeper understanding of Figure \ref{Test1_reg_plot}, we plot one of the 10 runs for 23 data points, 
% in Figure \ref{Test1_reg_visual_1}, and for 56 data points in Figure \ref{Test1_reg_visual_2}.
\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/1.pdf}
      \put (10,65) {BNN}
      \put (-5,40) {\small y}
  \end{overpic}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/2.pdf}
      \put (10,65) {BOHamiANN}
    \end{overpic}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/5.pdf}
      \put (10,65) {GP}
    \end{overpic}
    \end{minipage}
     
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/4.pdf}
      \put (10,65) {GMR}
      \put (-5,40) {\small y}
      \put (51,5) {\small x}
    \end{overpic}
    \end{minipage}
  \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/7_W.pdf}
      \put (10,65) {SPN}
     \end{overpic}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1/6.pdf}
        \put (10,65) {KDE}
      \end{overpic}
      \end{minipage}
  \caption{Plots visulising the results in figure at $n_{data} = 23$}
  \label{Test1_reg_visual_1}
\end{figure}
% \begin{figure}[H]
%   \centering
%   \begin{minipage}[b]{0.32\textwidth}
%     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/1.pdf}
%       \put (10,65) {BNN}
%       \put (-5,40) {\small y}
%   \end{overpic}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.32\textwidth}
%     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/2.pdf}
%       \put (10,65) {BOHamiANN}
%     \end{overpic}
%    \end{minipage}
%    \hfill
%    \begin{minipage}[b]{0.32\textwidth}
%     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/4.pdf}
%       \put (10,65) {GP}
%     \end{overpic}
%     \end{minipage}
     
%    \begin{minipage}[b]{0.32\textwidth}
%     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/3.pdf}
%       \put (10,65) {GMR}
%       \put (-5,40) {\small y}
%       \put (51,5) {\small x}
%     \end{overpic}
%     \end{minipage}
%   \hfill
%     \begin{minipage}[b]{0.32\textwidth}
%      \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/6.pdf}
%       \put (10,65) {SPN}
%      \end{overpic}
%     \end{minipage}
%     \hfill
%     \begin{minipage}[b]{0.32\textwidth}
%       \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test1b/5.pdf}
%         \put (10,65) {KDE}
%       \end{overpic}
%       \end{minipage}

%   \caption{Plots visulising the results in figure at $n_{data} = 133$}
%   \label{Test1_reg_visual_2}
% \end{figure}
\subsection*{Test2: Discontinuous problem}
As GP and BNN have a natural assumption of continuity we want to investigate their performance
on a discontinuous problem. We want to investigate their performance on the folloing step function, 
defined as 
$$f(x) = \sum_{i=1}^{13} u_i \bm{1}(I_{i+1}\leq x< I_{i+1}) + sin(x) \hspace{0.5cm} x \in ]-100,100]$$
where $\bm{1}$ denoted the indicator function and
\begin{align*}
  I &= [-100,  -83,  -71,  -60,  -49,  -31,   -9,    3,   14,26,   37,   60,   83,  100],\\
  u &= [181, 162, 144,  69, 106,  88, 200, 125, 144, 162, 181,88, 181, 200].
\end{align*}
Outside and on the boundaries $\{-100,100\}$ the function value is constant 200. This leads
to a more deficult problem than case 1. 
\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[width=\textwidth]{Figures/results_regression/Test2_dim_1_0.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{Figures/results_regression/Test2_dim_1_1.pdf}
   \end{minipage}
  \caption{Mean relative error (point estimate using the predictive mean) (left) and exponential mean predictive log probalility (right) as
  functions of number of training data points. All curves reprecent the average across 10 seeded runs for each
  model.}
  \label{Test2_reg_plot}
\end{figure}
Looking at Figure \ref{Test2_reg_plot} left we see that this is indeed harder to fit than Test 1, as
the reative error is not going down as fast. Comparing to Test 1 we here see that the mixtures are
doing as well and some times better than the discriminative models. If instead we used the mode for
the mixture regression models, we might see superior performance, as the prediction, will not be
continuous. Looing at the Figure \ref{Test2_reg_plot} right we see the same story as Test1 that the
mixtures regression has the best uncertainty quantification. Here SPN and KDE perfroms better than
Gaussian mixture regression, since the mixture components has no correlation beween $x$ and $y$,
which fits into the. Same story for BOHamiANN as Test1.
\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/1.pdf}
      \put (10,65) {BNN}
      \put (-5,40) {\small y}
  \end{overpic}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/2.pdf}
      \put (10,65) {BOHamiANN}
    \end{overpic}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/4.pdf}
      \put (10,65) {GP}
    \end{overpic}
    \end{minipage}
     
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/3.pdf}
      \put (10,65) {GMR}
      \put (-5,40) {\small y}
      \put (51,5) {\small x}
    \end{overpic}
    \end{minipage}
  \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/6.pdf}
      \put (10,65) {SPN}
     \end{overpic}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test2/5.pdf}
        \put (10,65) {KDE}
      \end{overpic}
      \end{minipage}

  \caption{Plots visulising the results in Figure \ref{Test2_reg_plot} at $n_{data} = ?$}
  \label{Test2_reg_visual}
\end{figure}

\subsection*{Test3: multi-modal problem}
The following problem is corresponding to a multimodal problem, which could occure in simulations with
two equally likely outcomes. We construct this problem to give the mixture models, 
an advantage over the discriminative models. It is defined as follows, 
$$f(x) = 50*g(x)+ 100 + 10*\sin(0.5\cdot x) + \epsilon \cdot (30 - g(x) \cdot 90), \hspace*{0.5cm}x \in
[-100,100],$$ 
where $\epsilon \sim \text{Cat}(0.5,0.5)$ and $g(x) = \text{sign}(x)+1 \in \{0,2\}$
is 0 for negative $x$ and 2 for positive $x$.

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[width=\textwidth]{Figures/results_regression/Test3b_dim_1_0.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{Figures/results_regression/Test3b_dim_1_1.pdf}
   \end{minipage}
  \caption{Plots visulising the results in above figure.}
  \label{Test3_reg_plot}
\end{figure}

In Figure \ref{Test3_reg_plot} left we see that none of the models are doing better than the mean
prediction. This is obvious since the data is symmetric and jumping random between two states. The
Bayesian neural networks are trying the fit the models, the GP is just turning itself into a mean
prediction. In the right plot we see just like previous that the data is parallel with the axis making it perfect
the SPN and KDE to fit. 


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/1.pdf}
      \put (10,65) {BNN}
      \put (-5,40) {\small y}
  \end{overpic}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/2.pdf}
      \put (10,65) {BOHamiANN}
    \end{overpic}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/4.pdf}
      \put (10,65) {GP}
    \end{overpic}
    \end{minipage}
     
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/3.pdf}
      \put (10,65) {GMR}
      \put (-5,40) {\small y}
      \put (51,5) {\small x}
    \end{overpic}
    \end{minipage}
  \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/6.pdf}
      \put (10,65) {SPN}
     \end{overpic}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test3/5.pdf}
        \put (10,65) {KDE}
      \end{overpic}
      \end{minipage}

  \caption{Plots visulising the results in figure at $n_{data} = ?$}
  \label{Test3_reg_visual}
\end{figure}

\subsection{Test4: anisotropic problem}
Finally, this problem has low frequency in the beginning but ends out with a very high frequency.
This is designed to be a difficult problem for the GP as this would need a different lengthscale
throughout the space.

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[width=\textwidth]{Figures/results_regression/Test4b_dim_1_0.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{Figures/results_regression/Test4b_dim_1_1.pdf}
   \end{minipage}
  \caption{Plots visulising the results in above figure.}
  \label{Test4_reg_plot}
\end{figure}

We however see that the GP does not need the ...


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/1.pdf}
      \put (10,65) {BNN}
      \put (-5,40) {\small y}
  \end{overpic}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/2.pdf}
      \put (10,65) {BOHamiANN}
    \end{overpic}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/4.pdf}
      \put (10,65) {GP}
    \end{overpic}
    \end{minipage}
     
   \begin{minipage}[b]{0.32\textwidth}
    \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/3.pdf}
      \put (10,65) {GMR}
      \put (-5,40) {\small y}
      \put (51,5) {\small x}
    \end{overpic}
    \end{minipage}
  \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/6.pdf}
      \put (10,65) {SPN}
     \end{overpic}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \begin{overpic}[trim=1cm 0.7cm 1.5cm 0.5cm,clip,width=\textwidth]{Figures/results_regression/Test4/5.pdf}
        \put (10,65) {KDE}
      \end{overpic}
      \end{minipage}

  \caption{Plots visulising the results in figure at $n_{data} = ?$}
  \label{Test4_reg_visual}
\end{figure}

\section{COCO}
Benchmark!!





\section{Mixture regression}

\begin{figure}
  \caption{Regression of a probabilistic objective function, is not a smart choice
  using anything else than a mixture regression model. Top we see the performance
  of 5 different regression models fitted to an increasing amount of training data, 
  the underlying function is tricky, as it jumps between multiple objective functions
  yielding a violation to most of the generative models, where most are capable of
  handling gaussian noise this is not gaussian noise and hence a very difficult problem. 
  This kind of objective function could definitely be relevant in certain cases.}
\end{figure}

One could define a generative story, flip a coin, then the data will
be fitted with this Gaussian.! 

\begin{figure}
  \caption{Plots visulising the results in above figure.}
\end{figure}

<data generating process>
Model do well when they are the data generating process, but if they are not, then
they do bad. If you collect all model, 

What model to chose? the standard answer of a Bayesian should be: Why choose? If there 
is uncertainty about them, then we can just average them. Pic the maximum would be frquencialistic.

Could we combine GP and SPN?

ensample of models ..
Simulation studies. 


% We evaluate the optimization methods on the BBOB-2015 noiseless
% testbed, which consists of 24 functions divided into five groups in terms of
% difficulty (see Table 3.1). These functions are a part of Comparing Continu-
% ous Optimizers framework (COCO) [77], which is a popular benchmarking
% testbed for continuous black-box optimization algorithms and allows for
% comprehensive evaluation of optimization methods over a set of functions
% with a wide range of characteristics (please refer to [57] for more details on
% the benchmark and specifications of each f

\section{Regression analysis of GP, BOHAMIANN and NumpyNN 1D}

\section{Regression analysis of GP, BOHAMIANN and NumpyNN 2D}

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_BOHAMIANN2.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_BOHAMIANN3.pdf}
   \end{minipage}
  
   \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_Gaussian Process - sklearn2.pdf}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.49\textwidth}
     \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_Gaussian Process - sklearn3.pdf}
    \end{minipage}

    \begin{minipage}[b]{0.49\textwidth}
      \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_Naive Gaussian Mixture Regression optimized2.pdf}
     \end{minipage}
     \hfill
     \begin{minipage}[b]{0.49\textwidth}
       \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_Naive Gaussian Mixture Regression optimized3.pdf}
    \end{minipage}
  \label{f1_reg_2D}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_numpyro neural network200-2002.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_numpyro neural network200-2003.pdf}
   \end{minipage}
  
  %  \begin{minipage}[b]{0.49\textwidth}
  %   \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_SPN regression optimized2.pdf}
  %  \end{minipage}
  %  \hfill
  %  \begin{minipage}[b]{0.49\textwidth}
  %    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f1_SPN regression optimized3.pdf}
  %   \end{minipage}

    \begin{minipage}[b]{0.49\textwidth}
      \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco/f1.pdf}
     \end{minipage}
     \hfill
  \label{f1_reg_2D}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_BOHAMIANN2.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_BOHAMIANN3.pdf}
   \end{minipage}
  
   \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_Gaussian Process - sklearn2.pdf}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.49\textwidth}
     \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_Gaussian Process - sklearn3.pdf}
    \end{minipage}

    \begin{minipage}[b]{0.49\textwidth}
      \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_Naive Gaussian Mixture Regression optimized-prior 12.pdf}
     \end{minipage}
     \hfill
     \begin{minipage}[b]{0.49\textwidth}
       \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_Naive Gaussian Mixture Regression optimized-prior 13.pdf}
    \end{minipage}
  \label{f23_reg_2D}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
   \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_numpyro neural network200-2002.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_numpyro neural network200-2003.pdf}
   \end{minipage}
  
   \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_SPN regression optimized2.pdf}
   \end{minipage}
   \hfill
   \begin{minipage}[b]{0.49\textwidth}
     \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco_reg/f23_SPN regression optimized3.pdf}
    \end{minipage}

    \begin{minipage}[b]{0.49\textwidth}
      \includegraphics[trim=1.2cm 0.7cm 2cm 1cm,clip,width=\textwidth]{Figures/coco/f23.png}
     \end{minipage}
     \hfill
  \label{f1_reg_2D}
\end{figure}



\begin{figure}[h]
  \caption{2D Regression plot for a few of the problems, with the correct }
\end{figure}

\section{Mixture regression on simple functions}
Choosing a good set of design parameters is crucial, 
the manipulation... 

\begin{figure}[h]
    \caption{Regression plot for one problem with all dims: Number of data points / dims, mean squared error, with bayesline mean prediction}
\end{figure}

\begin{figure}[h]
    \caption{Regression plot for anther problem}
\end{figure}

% \begin{figure}[h]
%     \centering
%         \begin{tabular}{c|ll|l|l}
%         \multicolumn{1}{l|}{Problem 2D} & Winner (rel error)                                              & Second                                                                                  & Third                              &  \\ \cline{1-4}
%         f1                                                      & \multicolumn{1}{c|}{GP (0.2)}                                                           & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Neural Network\\ (0.00001)\end{tabular}} & \multicolumn{1}{c|}{Naive (0.002)} &  \\
%         f2                                                      & \multicolumn{1}{c|}{Naive (0.002)}                                                      &                                                                                         &                                    &  \\
%         f3                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Neural Network\\ (0.00001)\end{tabular}} &                                                                                         &                                    &  \\
%         f4                                                      & \multicolumn{1}{l|}{}                                                                   &                                                                                         &                                    &  \\
%                                                                 & \multicolumn{1}{l|}{}                                                                   &                                                                                         &                                    & 
%         \end{tabular}
%     \caption{Table summarizing for all problems}
% \end{figure}

\begin{figure}[h]
    \centering
    \input{Tables/best_minimizer_group_1.tex}
    \caption{Distance to optima $f(x^{best})-f^*$ using Bayesian optimization with different surrogates
    and using expected improvement with a budget of $40$ samples for group 1: "5 separable functions"}
\end{figure}

\begin{figure}[h]
    \centering
    \input{Tables/best_minimizer_group_2.tex}
    \caption{Distance to optima $f(x^{best})-f^*$ using Bayesian optimization with different surrogates
    and using expected improvement with a budget of $40$ samples for group 2: "4 functions with low or moderate conditioning"}
\end{figure}
\begin{figure}[h]
    \centering
    \input{Tables/best_minimizer_group_3.tex}
    \caption{Distance to optima $f(x^{best})-f^*$ using Bayesian optimization with different surrogates
    and using expected improvement with a budget of $40$ samples for group 3: "5 functions with high conditioning, unimodal"}
\end{figure}
\begin{figure}[h]
    \centering
    \input{Tables/best_minimizer_group_4.tex}
    \caption{Distance to optima $f(x^{best})-f^*$ using Bayesian optimization with different surrogates
    and using expected improvement with a budget of $40$ samples for group 4: "5 multi-modal functions with adequate global structure"}
\end{figure}
\begin{figure}[h]
    \centering
    \input{Tables/best_minimizer_group_5.tex}
    \caption{Distance to optima $f(x^{best})-f^*$ using Bayesian optimization with different surrogates
    and using expected improvement with a budget of $40$ samples for group 5: "5 multi-modal functions with weak global structure"}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{BayesOpt plot: Number of iterations, distance to optima using EI, with bayesline random search}
\end{figure}


\begin{figure}[h]
    \centering
    \begin{minipage}[b]{0.32\textwidth}
     \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f1.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f2.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f3.png}
      %\caption{Rank}
    \end{minipage}
    
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f4.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f5.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f6.png}
    \end{minipage}
    

    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f7.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f8.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f9.png}
    \end{minipage}
    
    \begin{minipage}[b]{0.32\textwidth}
        \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f10.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f11.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f12.png}
    \end{minipage}
    \caption{Test functions f1 to f12}
    \label{2DBlockcyclic}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \begin{minipage}[b]{0.32\textwidth}
     \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f13.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
     \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f14.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f15.png}
      %\caption{Rank}
    \end{minipage}
    
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f16.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f17.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f18.png}
    \end{minipage}
    

    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f19.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f20.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f21.png}
    \end{minipage}
    
    \begin{minipage}[b]{0.32\textwidth}
        \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f22.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f23.png}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.32\textwidth}
      \includegraphics[trim=2.5cm 1.3cm 2.5cm 1.3cm,clip,width=\textwidth]{Figures/coco/f24.png}
    \end{minipage}
    \caption{Test functions f13-24}
    \label{f13-24}
  \end{figure}
  