\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\contentsline {section}{Abstract}{iii}{Doc-Start}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.0.1}%
\contentsline {section}{\numberline {1.1}Contribution}{2}{section.0.1.1}%
\contentsline {section}{\numberline {1.2}Related work}{3}{section.0.1.2}%
\contentsline {section}{\numberline {1.3}Structure of the thesis}{4}{section.0.1.3}%
\contentsline {section}{\numberline {1.4}Notation}{4}{section.0.1.4}%
\contentsline {chapter}{\numberline {2}Bayesian Optimization}{5}{chapter.0.2}%
\contentsline {section}{\numberline {2.1}Optimization methodology}{5}{section.0.2.1}%
\contentsline {subsection}{\numberline {2.1.1}When to use sample-efficient optimization}{6}{subsection.0.2.1.1}%
\contentsline {subsubsection}{Noisy objective functions}{7}{subsubsection*.4}%
\contentsline {section}{\numberline {2.2}Bayesian regression}{9}{section.0.2.2}%
\contentsline {subsection}{\numberline {2.2.1}surrogate model}{9}{subsection.0.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Inference of surrogate models}{9}{subsection.0.2.2.2}%
\contentsline {section}{\numberline {2.3}Acquisition function}{10}{section.0.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Expected improvement}{10}{subsection.0.2.3.1}%
\contentsline {subsubsection}{Exact expected improvement}{11}{subsubsection*.8}%
\contentsline {subsubsection}{Approximate expected improvement}{12}{subsubsection*.10}%
\contentsline {subsection}{\numberline {2.3.2}Lower confidense bound}{13}{subsection.0.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Entropy search}{13}{subsection.0.2.3.3}%
\contentsline {chapter}{\numberline {3}Discriminative surrogate models}{17}{chapter.0.3}%
\contentsline {section}{\numberline {3.1}Gaussian process surrogate}{17}{section.0.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Exact predictive distribution}{19}{subsection.0.3.1.1}%
\contentsline {section}{\numberline {3.2}Bayesian Neural Networks}{22}{section.0.3.2}%
\contentsline {subsection}{\numberline {3.2.1}No U-Turn sampling}{25}{subsection.0.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Adaptive stochatic HMC}{25}{subsection.0.3.2.2}%
\contentsline {chapter}{\numberline {4}Generative models as surrogate}{27}{chapter.0.4}%
\contentsline {section}{\numberline {4.1}Conditional distribution in a Bayesian setting}{27}{section.0.4.1}%
\contentsline {subsubsection}{Mean and variance of predictive distribution v1}{29}{subsubsection*.20}%
\contentsline {section}{\numberline {4.2}Conditional of mixture model}{29}{section.0.4.2}%
\contentsline {section}{\numberline {4.3}Kernel estimator regression}{30}{section.0.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Conditional of Kernel density estimator}{30}{subsection.0.4.3.1}%
\contentsline {section}{\numberline {4.4}Gaussian mixture regression}{31}{section.0.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Conditional of Gaussian mixture model}{31}{subsection.0.4.4.1}%
\contentsline {section}{\numberline {4.5}Sum product networks}{32}{section.0.4.5}%
\contentsline {subsection}{\numberline {4.5.1}SPN as mixture regression}{33}{subsection.0.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}SPN as a mixture model}{35}{subsection.0.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}Conditional of SPN}{35}{subsection.0.4.5.3}%
\contentsline {subsubsection}{calculation of responsibility}{36}{subsubsection*.26}%
\contentsline {section}{\numberline {4.6}Gaussian approximation of mixture regression}{36}{section.0.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Mean and variance of conditional SPN}{36}{subsection.0.4.6.1}%
\contentsline {section}{\numberline {4.7}Mixture model training}{37}{section.0.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Expectation-maximization for mixture models}{37}{subsection.0.4.7.1}%
\contentsline {chapter}{\numberline {5}Results}{41}{chapter.0.5}%
\contentsline {section}{\numberline {5.1}implementation}{41}{section.0.5.1}%
\contentsline {subsection}{\numberline {5.1.1}standardized data}{41}{subsection.0.5.1.1}%
\contentsline {section}{\numberline {5.2}Regression analysis}{41}{section.0.5.2}%
\contentsline {subsection}{\numberline {5.2.1}uncertainty quantification}{41}{subsection.0.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}prediction quantification}{42}{subsection.0.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}regression benchmark}{42}{subsection.0.5.2.3}%
\contentsline {section}{\numberline {5.3}Mixture regression}{42}{section.0.5.3}%
\contentsline {section}{\numberline {5.4}Regression analysis of GP, BOHAMIANN and NumpyNN 1D}{42}{section.0.5.4}%
\contentsline {section}{\numberline {5.5}Regression analysis of GP, BOHAMIANN and NumpyNN 2D}{42}{section.0.5.5}%
\contentsline {section}{\numberline {5.6}Mixture regression on simple functions}{42}{section.0.5.6}%
\contentsline {chapter}{\numberline {6}Conclusion and further work}{51}{chapter.0.6}%
\contentsline {section}{\numberline {6.1}further work}{51}{section.0.6.1}%
\contentsline {chapter}{Bibliography}{52}{chapter*.45}%
