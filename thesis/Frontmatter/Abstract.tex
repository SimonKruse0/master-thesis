\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}
% Abstract
%  1. Motivation. Why do we care?
Bayesian optimization is the leading methodology in sample-efficient optimization and
widely used in hyperparameter tuning in machine learning and deep learning. 

%  2. Problem formulation. What problem will we solve?
%     2.b. Current state. What have others done, and why is that not enough?
However, from a decision theory standpoint, assuming the probabilistic surrogate model to be correct
is crucial for the correct decision. We will investigate if other surrogate models could be better
than a Gaussian process (GP). 

%  3. Approach. What is our big idea? How did we solve it?
%     3.a. Analysis and experiments. What research did we do?
This thesis investigates surrogate models such as Mixture regression and Bayesian neural networks
and compares them against GP. 

%  4. Results. What is the answer?
%  5. Conclusions. What are the implications?
Results did not show any problem where the alternative surrogates were preferred. 





